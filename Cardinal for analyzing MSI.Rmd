---
title: "Cardinal to analyze MSI"
author: "Wenqing Yang (wy2374)"
date: "12/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(Cardinal)
```

## Visualizing MS images with `image()`

Use `image()` to plot ion images. Either `feature` or `mz` can be specified to determine which mass features should be plotted.

Suppose here's mz is 1200, give example 'mse'.

```{r image-mz, fig.height=4, fig.width=9}
image(mse, mz=1200)
```

Compare images plotted under different 'mz'.

```{r image-mz, fig.height=4, fig.width=9}
image(mse, mz=c(1200, 1500))
```

Multiplicative variance in spectral intensities can cause images to be noisy and dark due to hot spots.

Often, images may require some type of processing and enhancement to improve interpretation.

```{r image-smooth, fig.height=4, fig.width=9}
image(mse, mz=1200, smooth.image="gaussian")
```

Multiple images can be superposed with `superpose=TRUE`. Use `normalize.image="linear"` to normalize all images to the same intensity range.

```{r image-superpose, fig.height=4, fig.width=9}
image(mse2, mz=c(781, 1361), superpose=TRUE, normalize.image="linear")
```


3D imaging datasets can be plotted with `image3D()`.

```{r image3d}
set.seed(1)
mse3d <- simulateImage(preset=9, nruns=7, dim=c(7,7), npeaks=10,
						peakheight=c(2,4), representation="centroid")

image3D(mse3d, mz=c(1001, 1159), colorscale=plasma, cex=3, theta=30, phi=30)
```

## Region-of-interest selection

Use `selectROI()` to select regions-of-interest on an ion image. It is important to specify a subset so that selection is only made on a single experimental run, otherwise results may be unexpected. The form of `selectROI()` is the same as `image()`.

```{r select-ROI, eval=FALSE}
sampleA <- selectROI(mse, mz=1200, subset=run(mse) == "run0")
sampleB <- selectROI(mse, mz=1200, subset=run(mse) == "run1")
```

*Cardinal 2* provides statistical methods for both supervised and unsupervised analysis of mass spectrometry (MS) imaging experiments. Class comparison can also be performed, provided an appropriate experimental design and sample size.

Before statistical analysis, it is important to identify the statistical goal of the experiment:

- __Unsupervised analysis__. The data has no class labels or conditions, and we are interested in exploratory analysis to *discover* regions of interest in the data.

- __Supervised analysis__. The data has class labels and we want to train a statistical or machine learning model to *predict* the class labels of new data.

- __Class comparison__. The data has class labels or conditions, and we want to *test* whether the abundance of the mass features is different between conditions.

```{r eda-data, fig.height=3, fig.width=3, fig.align='center'}
set.seed(2020)
mse <- simulateImage(preset=2, npeaks=10, dim=c(20,20), sdnoise=0.5,
					peakheight=c(2,4), representation="centroid")

design <- makeFactor(circle=mse$circle, square=mse$square,
						bg=!(mse$circle | mse$square))

image(mse, design ~ x * y, key=TRUE)
```
Compared with mse

```{r eda-image, fig.height=6, fig.width=7}
image(mse)
```

## Principal components analysis (PCA)

Principal components analysis is an unsupervised dimension reduction technique. It reduces the data to some number of "principal components" that are a linear combination of the original mass features, where each component is orthogonal to the last, and explains as much of the variance in the data as possible.

Use `PCA()` to perform PCA on a `MSImagingExperiment`.

```{r pca}
pca <- PCA(mse, ncomp=3)
summary(pca)
```

We can see that the first two principal components explain most of the variation in the data.

```{r pca-image, fig.height=6, fig.width=7}
image(pca)
#image(pca, values="scores", superpose=FALSE, layout=c(1,3))
```

The loadings of the components show how each mass feature contributes to each component.

```{r pca-loadings, fig.height=2, fig.width=7}
plot(pca, values="loadings", superpose=FALSE, layout=c(1,3), lwd=2)
```

```{r pca-scores, fig.height=2.5, fig.width=4, fig.align='center'}
pca_scores <- DataFrame(resultData(pca, 1, "scores"))

plot(pca_scores, PC1 ~ PC2, groups=design, pch=20)
```

# Image segmentation

Segmentation (clustering) a dataset is a useful way to summarize an MS imaging experiment and discover regions of interest within the sample.

## Spatial shrunken centroids clustering

Spatially-aware nearest shrunken centroids clustering allows simultaneous image segmentation and feature selection.

A smoothing radius `r`, initial number of clusters `k`, and sparsity parameters `s` must be provided.

The larger the sparsity parameter `s`, the fewer mass features will contribute to the segmentation.

Spatial shrunken centroids may result in fewer clusters than the initial number of clusters `k`, so it is recommended to use a value for `k` that is larger than the expected number of clusters, and allow the method to automatically choose the number of clusters.

```{r ssc-clustering}
ssc <- spatialShrunkenCentroids(mse, r=1, k=5, s=c(0,3,6,9))

summary(ssc)
```


Plotting the predicted cluster probabilities shows a clear segmentation into the ground truth image.

```{r ssc-image, fig.height=3, fig.width=3}
image(ssc, model=list(s=9), values="probability")
```


## Spatial Dirichlet Gaussian mixture modeling

Spatially-aware Dirichlet Gaussian mixture models (spatial-DGMM) is a method of image segmentation applied to each mass feature individually, rather than the dataset as a whole.

This is useful for summarizing molecular ion images, and for discovering structures that clustering using all mass features together may miss.

```{r dgmm}
dgmm <- spatialDGMM(mse, r=1, k=5, method="adaptive")

summary(dgmm)
```

A different segmentation is fit for each mass feature.

```{r dgmm-image, fig.height=2, fig.width=7}
image(dgmm, model=list(feature=c(1,4,7)), layout=c(1,3))
```


Each image is modeled as a mixture of Gaussian distributions.

```{r dgmm-plot, fig.height=2, fig.width=7}
plot(dgmm, model=list(feature=c(1,4,7)), layout=c(1,3))
```